embedding_dim: 4096
attack_module: transformer.wte
hf_name: mosaicml/mpt-7b
attn_implementation: flash_attention_2
load_in_8bit: false
load_in_4bit: false
